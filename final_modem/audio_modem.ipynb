{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from audio_modem import audio_modem\n",
    "from scipy import signal\n",
    "import scipy\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import stats\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class receiver(audio_modem):\n",
    "    def __init__(self):\n",
    "        \n",
    "        audio_modem.__init__(self)\n",
    "        self.channel_freq = None\n",
    "        self.constellations = []\n",
    "        self.data_index = None\n",
    "        self.chirp_start = None\n",
    "        self.past_centers = []\n",
    "        self.past_angle = 0\n",
    "        self.past_gradient = 0\n",
    "        self.past_change = 0\n",
    "        self.entire_data = None\n",
    "        self.bits = None\n",
    "        self.file_name = None\n",
    "        self.sigma2 = None\n",
    "        self.pre_ldpc_data = []\n",
    "        self.corrected = []\n",
    "        self.first_decoded = []\n",
    "        self.times = 0\n",
    "\n",
    "    def set_bits_and_file_name(self, bits, file_name):\n",
    "        self.bits = bits\n",
    "        self.file_name = file_name\n",
    "    \n",
    "    def find_start_index(self, data):\n",
    "        # Find Chirp Start\n",
    "        # x and y are the time signals to be compared\n",
    "        x = self.chirp\n",
    "        cross_correlation = []\n",
    "        plot_data = data\n",
    "        data = data[:300000]\n",
    "        print(len(data))\n",
    "        n = len(x)\n",
    "        N = len(data)\n",
    "        lags = np.arange(-n + 1, N) \n",
    "        cross_correlation.append(scipy.signal.correlate(data, x,mode='full', method='fft'))\n",
    "        cross_correlation = np.array(cross_correlation)\n",
    "        cross_correlation = np.reshape(cross_correlation, cross_correlation.shape[1])\n",
    "        print(cross_correlation.shape)\n",
    "        #plt.plot(cross_correlation)\n",
    "        #plt.show()\n",
    "        cross_correlation = np.abs(cross_correlation)\n",
    "        cross_correlation = uniform_filter1d(cross_correlation, size=5)\n",
    "        #plt.plot(cross_correlation)\n",
    "        #plt.show()\n",
    "        max_index = np.argmax(cross_correlation)\n",
    "        self.chirp_start = lags[max_index]\n",
    "        positions = np.arange(0, len(data))\n",
    "        #plt.plot(positions[:lags[max_index] -1024],data[:lags[max_index] -1024])\n",
    "        #plt.plot(positions[lags[max_index] - 1024:lags[max_index] +len(self.chirp_p_s) - 1024],data[lags[max_index] - 1024:lags[max_index] +len(self.chirp_p_s) - 1024], color='r')\n",
    "        #plt.plot(positions[lags[max_index] +len(self.chirp_p_s) - 1024:],data[lags[max_index] +len(self.chirp_p_s) - 1024:], color='g')\n",
    "        #plt.show()\n",
    "        return lags[max_index], cross_correlation, lags\n",
    "    \n",
    "    def find_end_index(self, data):\n",
    "        # Find Chirp End\n",
    "        # x and y are the time signals to be compared\n",
    "        x = self.chirp\n",
    "        cross_correlation = []\n",
    "        plot_data = data\n",
    "        data = data[350000:]\n",
    "        print(len(data))\n",
    "        n = len(x)\n",
    "        N = len(data)\n",
    "        lags = np.arange(-n + 1, N) \n",
    "        cross_correlation.append(scipy.signal.correlate(data, x,mode='full', method='fft'))\n",
    "        cross_correlation = np.array(cross_correlation)\n",
    "        cross_correlation = np.reshape(cross_correlation, cross_correlation.shape[1])\n",
    "    \n",
    "        cross_correlation = np.abs(cross_correlation)\n",
    "        cross_correlation = uniform_filter1d(cross_correlation, size=5)\n",
    "\n",
    "        max_index = np.argmax(cross_correlation)\n",
    "        self.chirp_start = lags[max_index]\n",
    "        positions = np.arange(0, len(data))\n",
    "        \n",
    "        return lags[max_index] + 350000, cross_correlation, lags\n",
    "    \n",
    "    def channel_estimation(self, block, ideal_block):\n",
    "        # Find Channel Response\n",
    "        # H = Y/X\n",
    "        # Y = Recieved OFDM Blocks\n",
    "        # X = Ideal OFDM Blocks\n",
    "        # H = Channel Response\n",
    "        self.channel_freq = np.true_divide(block, ideal_block, out=np.zeros_like(block), where=ideal_block!=0).astype(complex)\n",
    "        self.channel_freq[0] = 1\n",
    "        self.channel_freq[self.ofdm_symbol_size // 2] = 1\n",
    "\n",
    "        time_freq = np.fft.ifft(self.channel_freq)\n",
    "        time_freq = time_freq.real\n",
    "        filter = self.ofdm_symbol_size\n",
    "        time_freq = time_freq[0:filter]\n",
    "        time_freq = np.pad(time_freq, (0, self.ofdm_symbol_size - filter), 'constant', constant_values=(0, 0))\n",
    "        channel_freq = np.fft.fft(time_freq)\n",
    "        self.channel_freq = channel_freq\n",
    "        return self.channel_freq\n",
    "\n",
    "    def find_data_index(self, data, start_index):\n",
    "        # Find Data Start\n",
    "        self.data_index = start_index + len(self.chirp_p_s) - self.ofdm_prefix_size\n",
    "        return self.data_index\n",
    "    \n",
    "    def calculate_sigma2_five_block(self, recieved, ideal):\n",
    "        ideal = ideal * self.channel_freq\n",
    "        ideal = np.concatenate(ideal)\n",
    "        recieved = np.concatenate(recieved)\n",
    "        real_square_error = (recieved.real - ideal.real) ** 2\n",
    "        real_square_error = real_square_error.astype(np.float32)\n",
    "        # print(real_square_error)\n",
    "        imag_square_error = (recieved.imag - ideal.imag) ** 2\n",
    "        imag_square_error = imag_square_error.astype(np.float32)\n",
    "        # print(imag_square_error)\n",
    "        all_errors = np.concatenate((real_square_error, imag_square_error))\n",
    "\n",
    "        sigma2 = np.mean(all_errors)\n",
    "        print(\"second guess sigma2\", sigma2) # Should be ~ 0.1 ish for ideal channel?\n",
    "        return sigma2\n",
    "\n",
    "    def calculate_sigma2(self, recieved, ideal):\n",
    "        # TODO: CHECK WITH MAX CORRECT\n",
    "        # Calculate Noise Power\n",
    "        # sigma2 = 1/N * \\sum_{k=1}^{N} |Y_k - H_kX_k|^2\n",
    "        # Y = Recieved OFDM Blocks\n",
    "        # X = Ideal OFDM Blocks\n",
    "        # H = Channel Response\n",
    "        # sigma2 = Noise Power\n",
    "        ideal = ideal * self.channel_freq[self.ofdm_bin_min:self.ofdm_bin_max+1]\n",
    "        ideal = np.concatenate(ideal)\n",
    "        recieved = np.concatenate(recieved)\n",
    "        real_square_error = (recieved.real - ideal.real) ** 2\n",
    "        real_square_error = real_square_error.astype(np.float32)\n",
    "        # print(real_square_error)\n",
    "        imag_square_error = (recieved.imag - ideal.imag) ** 2\n",
    "        imag_square_error = imag_square_error.astype(np.float32)\n",
    "        # print(imag_square_error)\n",
    "        all_errors = np.concatenate((real_square_error, imag_square_error))\n",
    "\n",
    "        sigma2 = np.mean(all_errors)\n",
    "        print(\"second guess sigma2\", sigma2) # Should be ~ 0.1 ish for ideal channel?\n",
    "        return sigma2\n",
    "    \n",
    "    def calculate_sigma2_one_block(self, recieved):\n",
    "        dec = []\n",
    "        for i in recieved:\n",
    "            if np.real(i) >= 0 and np.imag(i) >= 0:\n",
    "                dec.append(1 + 1j)\n",
    "            elif np.real(i) <= 0 and np.imag(i) >= 0:\n",
    "                dec.append(-1 + 1j)\n",
    "            elif np.real(i) <= 0 and np.imag(i) <= 0:\n",
    "                dec.append(-1 - 1j)\n",
    "            elif np.real(i) >= 0 and np.imag(i) <= 0:\n",
    "                dec.append(1 - 1j)\n",
    "        dec = np.array(dec)\n",
    "\n",
    "        real_square_error = (recieved.real - dec.real) ** 2\n",
    "        real_square_error = real_square_error.astype(np.float32)\n",
    "        # print(real_square_error)\n",
    "        imag_square_error = (recieved.imag - dec.imag) ** 2\n",
    "        imag_square_error = imag_square_error.astype(np.float32)\n",
    "\n",
    "        all_errors = np.concatenate((real_square_error, imag_square_error))\n",
    "\n",
    "        sigma2 = np.mean(all_errors)\n",
    "        return sigma2\n",
    "              \n",
    "    def combined_correction(self, current_OFDM):\n",
    "        past_angle = self.past_angle\n",
    "        past_gradient = self.past_gradient\n",
    "        past_centers = self.past_centers\n",
    "        past_change = self.past_change\n",
    "\n",
    "        corrected = current_OFDM\n",
    "        corrected = corrected * np.exp(-1j * past_gradient)\n",
    "        corrected = corrected * np.exp(-1j * past_angle)\n",
    "        centers = []\n",
    "        d = []\n",
    "        past_centers = np.asarray(past_centers)\n",
    "        \"\"\"cluster_1 = []\n",
    "        cluster_2 = []\n",
    "        cluster_3 = []\n",
    "        cluster_4 = []\"\"\"\n",
    "        labels = []\n",
    "        inti = [[1, 1], [1, -1], [-1, -1], [-1, 1]]\n",
    "        inti = np.array(inti)\n",
    "        inti_complex = inti[:, 0] + 1j * inti[:, 1]\n",
    "        if past_centers.shape[0] != 0:\n",
    "            kmeans = KMeans(n_clusters=4, init=inti, random_state=0 ).fit(np.array([np.real(corrected), np.imag(corrected)]).T)\n",
    "            centers = kmeans.cluster_centers_\n",
    "            labels = kmeans.labels_\n",
    "            complex_centers = centers[:, 0] + 1j * centers[:, 1]\n",
    "            #print(\"Centers: \", complex_centers)\n",
    "            complex_angles = np.angle(complex_centers)\n",
    "            inti_angles = np.angle(inti_complex)\n",
    "            \"\"\"distance = complex_centers - inti_complex\"\"\"\n",
    "            angle_diff = complex_angles - inti_angles\n",
    "            angle = np.array(angle_diff)\n",
    "            #print(\"distance\", d)\n",
    "            #angle = np.angle(d)\n",
    "            #print(\"angle\", angle)\n",
    "            \"\"\"for i in range(len(angle)):\n",
    "                if angle[i] < 0:\n",
    "                    angle[i] = 2 * np.pi + angle[i]\"\"\"\n",
    "            angle = np.mean(angle) #- np.pi\n",
    "            #print(\"mean angle\", angle)\n",
    "            \"\"\"if np.abs(angle) > 0.3:\n",
    "                angle = 0\"\"\"\n",
    "            #print(angle)\n",
    "            corrected = corrected * np.exp(-1j * angle)\n",
    "            \"\"\"angle = np.mean(angle)\n",
    "            if angle < 0:\n",
    "                angle = 2 * np.pi + angle\n",
    "            corrected = corrected * np.exp(-1j * angle)\"\"\"\n",
    "            past_angle += angle \n",
    "        else:\n",
    "            kmeans = KMeans(n_clusters=4, init=inti ).fit(np.array([np.real(corrected), np.imag(corrected)]).T)\n",
    "            centers = kmeans.cluster_centers_\n",
    "            labels = kmeans.labels_\n",
    "            complex_centers = centers[:, 0] + 1j * centers[:, 1]\n",
    "\n",
    "        predicted_ideal_angle = []\n",
    "        for i in range(len(labels)):\n",
    "            predicted_ideal_angle.append(np.angle(complex_centers[labels[i]]))\n",
    "        predicted_ideal_angle = np.array(predicted_ideal_angle)\n",
    "        predicted_ideal_angle = np.unwrap(predicted_ideal_angle)\n",
    "        known_angles = np.angle(corrected)\n",
    "        known_angles = np.unwrap(known_angles)\n",
    "        diff = known_angles - predicted_ideal_angle\n",
    "        diff = np.unwrap(diff)\n",
    "\n",
    "\n",
    "        for index, i in enumerate(diff):\n",
    "            if i > np.pi + 1:\n",
    "                diff[index] = diff[index] - 2 * np.pi\n",
    "            if i < -np.pi - 1:\n",
    "                diff[index] = diff[index] + 2 * np.pi\n",
    "        positions = np.arange(len(corrected)) \n",
    "        grad, intercept, r_value, p_value, std_err = stats.linregress(positions, diff)\n",
    "        if math.isclose(intercept, 2* np.pi, abs_tol=2):\n",
    "            intercept = intercept - 2 * np.pi\n",
    "        if math.isclose(intercept, -2* np.pi, abs_tol=2):\n",
    "            intercept = intercept + 2 * np.pi\n",
    "\n",
    "        gradient_2 = grad * np.arange(len(current_OFDM)) #+ intercept\n",
    "\n",
    "        if np.mean(np.abs(gradient_2)) > 1:\n",
    "            gradient_2 = self.past_change\n",
    "        corrected = corrected * np.exp(-1j * gradient_2)\n",
    "        gradient = gradient_2 + past_gradient\n",
    "\n",
    "        self.past_change = gradient_2\n",
    "\n",
    "        self.past_centers = centers\n",
    "        self.past_angle = past_angle\n",
    "        self.past_gradient = gradient\n",
    "        #print(\"Gradient: \", grad, \"Intercept: \", intercept)\n",
    "        #print(\"Angle: \", past_angle)\n",
    "        \n",
    "        #print(\"Gradient 2: \", gradient_2)\n",
    "        \"\"\"plt.plot(positions, gradient_2)\n",
    "        plt.show()\"\"\"\n",
    "        \n",
    "        return corrected\n",
    "\n",
    "    def ofdm_one_block(self, data_block, sigma2):\n",
    "        \"\"\"Decode one block of data\"\"\"\n",
    "        assert len(data_block) == self.ofdm_symbol_size\n",
    "\n",
    "        # DFT\n",
    "        freq = np.fft.fft(data_block)\n",
    "        \n",
    "        # Divide by Channel Response\n",
    "        freq = freq / self.channel_freq\n",
    "\n",
    "        # Remove Complex Conjugate Bins\n",
    "        freq = freq[1:2048]\n",
    "\n",
    "        # Remove Watermark\n",
    "        watermark = self.generate_known_ofdm_block_mod4()\n",
    "        watermark = watermark\n",
    "        # print(\"Watermark: \", watermark[0:5])\n",
    "\n",
    "        # Rotate Watermark\n",
    "        freq = freq * np.exp(-1j * watermark * np.pi / 2)\n",
    "        corrected = freq\n",
    "        corrected = self.combined_correction(freq[self.ofdm_bin_min-1:self.ofdm_bin_max])\n",
    "        corrected = corrected\n",
    "        self.corrected.append(corrected * self.channel_freq[self.ofdm_bin_min:self.ofdm_bin_max+1])\n",
    "\n",
    "        self.constellations.extend(corrected)\n",
    "        # Find Closest Constellation Point\n",
    "        decoded = []\n",
    "        llrs = []\n",
    "        for index, i in enumerate(corrected):\n",
    "            decoded.extend(self.constellation_point_to_binary(i))\n",
    "\n",
    "            # Find LLRs by using distance from axes for soft LDPC decoding:\n",
    "            # L_1(y) = c_k \\times c_k^* y'_i / \\sigma ^ 2\n",
    "            l1 = self.channel_freq[index + self.ofdm_bin_min] * np.conj(self.channel_freq[index + self.ofdm_bin_min]) * np.imag(i) / sigma2\n",
    "            # L_2(y) = c_k \\times c_k^* y'_r / \\sigma ^ 2 ... from Jossy LDPC Paper\n",
    "            l2 = self.channel_freq[index + self.ofdm_bin_min] * np.conj(self.channel_freq[index + self.ofdm_bin_min]) * np.real(i) / sigma2\n",
    "            llrs.extend([l1.real, l2.real])\n",
    "\n",
    "        return decoded, llrs\n",
    "\n",
    "    def ofdm_one_block_2(self, data_block, sigma2):\n",
    "        data_block = np.array(data_block)\n",
    "        data_block = np.reshape(data_block, len(data_block))\n",
    "\n",
    "        assert len(data_block) == self.bin_length\n",
    "\n",
    "        data_block = data_block / self.channel_freq[self.ofdm_bin_min:self.ofdm_bin_max+1]\n",
    "\n",
    "        self.corrected.append(data_block * self.channel_freq[self.ofdm_bin_min:self.ofdm_bin_max+1])\n",
    "        self.constellations.extend(data_block)\n",
    "\n",
    "        decoded = []\n",
    "        llrs = []\n",
    "        for index, i in enumerate(data_block):\n",
    "            decoded.extend(self.constellation_point_to_binary(i))\n",
    "\n",
    "            l1 = self.channel_freq[index + self.ofdm_bin_min] * np.conj(self.channel_freq[index + self.ofdm_bin_min]) * np.imag(i) / sigma2\n",
    "            l2 = self.channel_freq[index + self.ofdm_bin_min] * np.conj(self.channel_freq[index + self.ofdm_bin_min]) * np.real(i) / sigma2\n",
    "            llrs.extend([l1.real, l2.real])\n",
    "\n",
    "        return decoded, llrs\n",
    "\n",
    "    def ldpc_decode_one_block(self, to_decode, llrs, mode=\"soft\"):\n",
    "        to_decode = np.array(to_decode)\n",
    "        to_decode = np.reshape(to_decode, len(to_decode))\n",
    "        llrs = np.array(llrs)\n",
    "        llrs = np.reshape(llrs, len(llrs))\n",
    "        decoded = []\n",
    "\n",
    "        assert len(to_decode) == len(llrs)\n",
    "        assert len(to_decode) == self.c.N\n",
    "\n",
    "        if mode == \"soft\":\n",
    "            decoded_block, iters = self.c.decode(llrs)\n",
    "            decoded_temp = []\n",
    "            decoded_temp += ([1 if k < 0 else 0 for k in decoded_block])\n",
    "            self.first_decoded.append(decoded_temp)\n",
    "\n",
    "            decoded_block = decoded_block[:-(self.c.K)] # No idea what the extra information is\n",
    "            decoded += ([1 if k < 0 else 0 for k in decoded_block])\n",
    "\n",
    "        elif mode == \"hard\":\n",
    "            i = to_decode.copy()\n",
    "            i = 10 * (0.5 - i) # Do weightings\n",
    "\n",
    "            decoded_block, iters = self.c.decode(i)\n",
    "            decoded_block = decoded_block[:-(self.c.K)] # No idea what the extra information is\n",
    "            decoded += ([1 if k < 0 else 0 for k in decoded_block])\n",
    "        else:\n",
    "            raise Exception(\"Only 'hard' and 'soft' are valid ldpc decoding modes\")\n",
    "            \n",
    "        return decoded\n",
    "\n",
    "    def data_block_processing(self, five_blocks = False):\n",
    "        all_data = []\n",
    "        actual_data = self.entire_data\n",
    "        ofdm_block_one = actual_data[:self.ofdm_symbol_size+self.ofdm_prefix_size]\n",
    "        ofdm_block_one = ofdm_block_one[self.ofdm_prefix_size:]\n",
    "        self.pre_ldpc_data = []\n",
    "        ideal_block = self.generate_known_ofdm_block()\n",
    "\n",
    "        assert len(ofdm_block_one) == self.ofdm_symbol_size\n",
    "\n",
    "        channel_freq = self.channel_estimation(np.fft.fft(ofdm_block_one), ideal_block)\n",
    "        self.channel_freq = channel_freq\n",
    "\n",
    "        index = 1\n",
    "        if five_blocks == False:\n",
    "            ofdm_freq = np.fft.fft(ofdm_block_one)\n",
    "            self.sigma2 = self.calculate_sigma2_one_block(ofdm_freq) // 2\n",
    "            ofdm_freq = ofdm_freq / channel_freq\n",
    "            ofdm_freq = ofdm_freq[1:2048]\n",
    "            corrected = self.combined_correction(ofdm_freq[self.ofdm_bin_min-1:self.ofdm_bin_max])\n",
    "        else:\n",
    "            ofdm_block_two = actual_data[self.ofdm_symbol_size+self.ofdm_prefix_size: 2 * (self.ofdm_symbol_size + self.ofdm_prefix_size)]\n",
    "            ofdm_block_two = ofdm_block_two[self.ofdm_prefix_size:]\n",
    "            ofdm_block_three = actual_data[2 * (self.ofdm_symbol_size + self.ofdm_prefix_size): 3 * (self.ofdm_symbol_size + self.ofdm_prefix_size)]\n",
    "            ofdm_block_three = ofdm_block_three[self.ofdm_prefix_size:]\n",
    "            ofdm_block_four = actual_data[3 * (self.ofdm_symbol_size + self.ofdm_prefix_size): 4 * (self.ofdm_symbol_size + self.ofdm_prefix_size)]\n",
    "            ofdm_block_four = ofdm_block_four[self.ofdm_prefix_size:]\n",
    "            ofdm_block_five = actual_data[4 * (self.ofdm_symbol_size + self.ofdm_prefix_size): 5 * (self.ofdm_symbol_size + self.ofdm_prefix_size)]\n",
    "            ofdm_block_five = ofdm_block_five[self.ofdm_prefix_size:]\n",
    "\n",
    "            channel_freq_2 = self.channel_estimation(np.fft.fft(ofdm_block_two), ideal_block)\n",
    "            channel_freq_3 = self.channel_estimation(np.fft.fft(ofdm_block_three), ideal_block)\n",
    "            channel_freq_4 = self.channel_estimation(np.fft.fft(ofdm_block_four), ideal_block)\n",
    "            channel_freq_5 = self.channel_estimation(np.fft.fft(ofdm_block_five), ideal_block)\n",
    "\n",
    "            channel_freq = (channel_freq + channel_freq_2 + channel_freq_3 + channel_freq_4 + channel_freq_5) / 5\n",
    "            self.channel_freq = channel_freq\n",
    "\n",
    "            ofdm_freq_1 = np.fft.fft(ofdm_block_one)\n",
    "            ofdm_freq_2 = np.fft.fft(ofdm_block_two)\n",
    "            ofdm_freq_3 = np.fft.fft(ofdm_block_three)\n",
    "            ofdm_freq_4 = np.fft.fft(ofdm_block_four)\n",
    "            ofdm_freq_5 = np.fft.fft(ofdm_block_five)\n",
    "\n",
    "            ofdm_freq_1 = ofdm_freq_1 / channel_freq\n",
    "            ofdm_freq_2 = ofdm_freq_2 / channel_freq\n",
    "            ofdm_freq_3 = ofdm_freq_3 / channel_freq\n",
    "            ofdm_freq_4 = ofdm_freq_4 / channel_freq\n",
    "            ofdm_freq_5 = ofdm_freq_5 / channel_freq\n",
    "\n",
    "            ofdm_freq_1 = ofdm_freq_1[1:2048]\n",
    "            ofdm_freq_2 = ofdm_freq_2[1:2048]\n",
    "            ofdm_freq_3 = ofdm_freq_3[1:2048]\n",
    "            ofdm_freq_4 = ofdm_freq_4[1:2048]\n",
    "            ofdm_freq_5 = ofdm_freq_5[1:2048]\n",
    "\n",
    "            corrected_1 = self.combined_correction(ofdm_freq_1[self.ofdm_bin_min-1:self.ofdm_bin_max])\n",
    "            corrected_2 = self.combined_correction(ofdm_freq_2[self.ofdm_bin_min-1:self.ofdm_bin_max])\n",
    "            corrected_3 = self.combined_correction(ofdm_freq_3[self.ofdm_bin_min-1:self.ofdm_bin_max])\n",
    "            corrected_4 = self.combined_correction(ofdm_freq_4[self.ofdm_bin_min-1:self.ofdm_bin_max])\n",
    "            corrected_5 = self.combined_correction(ofdm_freq_5[self.ofdm_bin_min-1:self.ofdm_bin_max])\n",
    "\n",
    "            ideal_block = self.generate_known_ofdm_block()\n",
    "            self.sigma2 = self.calculate_sigma2_five_block([corrected_1, corrected_2, corrected_3, corrected_4, corrected_5], [ideal_block, ideal_block, ideal_block, ideal_block, ideal_block])\n",
    "            index = 5\n",
    "\n",
    "        \n",
    "        while len(all_data) < self.bits:\n",
    "            #print(\"\\n\")\n",
    "            #print(\"Index: \", index)\n",
    "            ofdm_block = actual_data[index * (self.ofdm_symbol_size + self.ofdm_prefix_size): (index + 1) * (self.ofdm_symbol_size + self.ofdm_prefix_size)]\n",
    "            ofdm_block = ofdm_block[self.ofdm_prefix_size:]\n",
    "\n",
    "            #sigma2 = self.calculate_sigma2_one_block(ofdm_block)\n",
    "            #print(len(ofdm_block))\n",
    "            assert len(ofdm_block) == self.ofdm_symbol_size\n",
    "\n",
    "            data_bins, llrs = self.ofdm_one_block(ofdm_block, self.sigma2)\n",
    "\n",
    "            self.pre_ldpc_data.extend(data_bins)\n",
    "\n",
    "            #decoded = self.ldpc_decode_one_block(data_bins, llrs)\n",
    "\n",
    "            all_data.extend(data_bins[:-(self.c.K)])\n",
    "            index += 1\n",
    "        \n",
    "        self.corrected = np.array(self.corrected)\n",
    "        self.first_decoded = np.array(self.first_decoded)\n",
    "        #return self.data_block_processing_part_2()\n",
    "\n",
    "        all_data = all_data[:self.bits]\n",
    "        return all_data\n",
    "    \n",
    "    def data_block_processing_part_2(self):\n",
    "        corrected = self.corrected.copy()\n",
    "        first_decoded = self.first_decoded.copy()\n",
    "        first_decoded_constellations = []\n",
    "\n",
    "        for i in first_decoded:\n",
    "            first_decoded_constellations.append(self.binary_to_constellation_point(i))\n",
    "        \n",
    "        first_decoded_constellations = np.array(first_decoded_constellations)\n",
    "\n",
    "        temp_channels = []\n",
    "        for index, i in enumerate(corrected):\n",
    "            #print(index, i.shape, first_decoded_constellations[index].shape)\n",
    "            temp_channels.append(i / first_decoded_constellations[index])\n",
    "        \n",
    "        temp_channels = np.array(temp_channels)\n",
    "\n",
    "        mean = np.mean(temp_channels, axis=0)\n",
    "\n",
    "        plt.plot(np.abs(self.channel_freq))\n",
    "\n",
    "        self.channel_freq[self.ofdm_bin_min:self.ofdm_bin_max+1] = mean\n",
    "\n",
    "        plt.plot(np.abs(self.channel_freq), color='r')\n",
    "        plt.show()\n",
    "\n",
    "        self.sigma2 = self.calculate_sigma2(corrected, first_decoded_constellations)\n",
    "\n",
    "        self.pre_ldpc_data = []\n",
    "        self.corrected = []\n",
    "        self.first_decoded = []\n",
    "        self.all_data = []\n",
    "        self.constellations = []\n",
    "        \n",
    "        for index, i in enumerate(corrected):\n",
    "            data_bins, llrs = self.ofdm_one_block_2(i, self.sigma2)\n",
    "            self.pre_ldpc_data.extend(data_bins)\n",
    "\n",
    "            decoded = self.ldpc_decode_one_block(data_bins, llrs)\n",
    "\n",
    "            self.all_data.extend(decoded)\n",
    "\n",
    "        self.corrected = np.array(self.corrected)\n",
    "        self.first_decoded = np.array(self.first_decoded)\n",
    "\n",
    "        all_data = self.all_data\n",
    "        self.times += 1\n",
    "        if self.times == 1:\n",
    "            return all_data\n",
    "        else:\n",
    "            return self.data_block_processing_part_2()\n",
    "     \n",
    "    def extract_header(self, data):\n",
    "        # Extract Header\n",
    "        data = np.array(data)\n",
    "        data = np.reshape(data, len(data))\n",
    "\n",
    "        null_character = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        null_character = np.array(null_character)\n",
    "\n",
    "        num_nulls = 0\n",
    "        name_start = 0\n",
    "        header_start = 0\n",
    "        name = []\n",
    "        header = []\n",
    "        restofdata = []\n",
    "        for i in range(0, len(data), 8):\n",
    "            if ((data[i:i+8] == null_character).all()):\n",
    "                #print(i)\n",
    "                num_nulls += 1\n",
    "                if num_nulls == 2:\n",
    "                    name_start = i+8\n",
    "                if num_nulls == 3:\n",
    "                    name.extend(data[name_start:i])\n",
    "                if num_nulls == 4:\n",
    "                    header_start = i+8\n",
    "                if num_nulls == 5:\n",
    "                    header.extend(data[header_start:i])\n",
    "                if num_nulls == 6:\n",
    "                    restofdata.extend(data[i+8:])\n",
    "                    print('data start:', i+8)\n",
    "                    break\n",
    "        #print(\"Name: \", name)\n",
    "        #print(\"Header: \", header)\n",
    "        file_name = self.decode_text(name)\n",
    "        bits = self.decode_text(header)\n",
    "\n",
    "        print(\"File Name: \", file_name)\n",
    "        print(\"Header: \", bits)\n",
    "\n",
    "        self.set_bits_and_file_name(bits, file_name)\n",
    "\n",
    "        return restofdata\n",
    "\n",
    "    def listen(self):\n",
    "        self.entire_data = np.loadtxt('../malachy_testing4.csv', delimiter = \",\", dtype = \"float\")\n",
    "        \n",
    "    def decode_text(self, binary_data):\n",
    "        binary_data = np.array(binary_data).astype(\"str\")\n",
    "\n",
    "        ascii = [int(''.join(binary_data[i:i+8]), 2) for i in range(0, len(binary_data), 8)]\n",
    "\n",
    "        return ''.join([chr(i) for i in ascii])\n",
    "    \n",
    "    def save_decoded_file(self, data_arr, size):\n",
    "        print(len(data_arr))\n",
    "        print(data_arr[:100])\n",
    "        data = ''.join(str(i) for i in data_arr)\n",
    "        byte = int(data, 2).to_bytes(size, 'big')\n",
    "        print(len(data))\n",
    "        output = open(self.file_name, \"wb\")\n",
    "        output.write(byte)\n",
    "        output.close()\n",
    "\n",
    "    def start(self):\n",
    "        self.listen()\n",
    "        #print(self.entire_data.shape)\n",
    "        start_index, cross_correlation, lags = self.find_start_index(self.entire_data)\n",
    "        end_index, cross_correlation, lags = self.find_end_index(self.entire_data)\n",
    "        end_index = end_index - self.ofdm_prefix_size\n",
    "        data_index = self.find_data_index(self.entire_data, start_index)\n",
    "        data_length = end_index - data_index\n",
    "        #print(\"Data Index: \", data_length)\n",
    "        num_blocks = int(np.ceil(data_length / (self.ofdm_symbol_size + self.ofdm_prefix_size)))\n",
    "        self.entire_data = self.entire_data[data_index:int(data_index + (num_blocks+1) * (self.ofdm_symbol_size + self.ofdm_prefix_size) + 1)]\n",
    "        self.bits = int(num_blocks * self.c.K)\n",
    "        #print(\"num_blocks: \", num_blocks)\n",
    "        self.bits = 30704\n",
    "        #print(\"bits: \", self.bits)\n",
    "        data = self.data_block_processing()\n",
    "        print(\"Data: \", data[0:100])\n",
    "        all_data = self.extract_header(data)\n",
    "        self.bits = int(self.bits)\n",
    "        all_data = all_data\n",
    "        self.save_decoded_file(all_data, self.bits)\n",
    "        return all_data\n",
    "\n",
    "def success(a, b):\n",
    "    \"\"\"find the percentage difference between two lists\"\"\"\n",
    "    successes = 0\n",
    "    wrong_indices = []\n",
    "    for index, i in enumerate(a):\n",
    "        if i == b[index]:\n",
    "            successes += 1 / len(a)\n",
    "        else:\n",
    "            wrong_indices.append(index)\n",
    "    #print(\"Wrong Indices: \", wrong_indices)\n",
    "    return successes\n",
    "\n",
    "from transmitter import transmitter\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    t =  transmitter()\n",
    "\n",
    "    transmitted_bits = t.process_file(\"hamlet_c.txt\")\n",
    "    print(transmitted_bits[:100])\n",
    "    ldpc_bits = t.ldpc_encode(transmitted_bits)\n",
    "\n",
    "    r = receiver()\n",
    "\n",
    "    # print(r.decode_text([0, 1, 0, 0, 0, 0, 0, 1]))\n",
    "\n",
    "    r.set_bits_and_file_name(30704,'asdf')\n",
    "\n",
    "    r.listen()\n",
    "\n",
    "    binary_data = r.start()\n",
    "    print(transmitted_bits[:100])\n",
    "    print(ldpc_bits[:100])\n",
    "    print(binary_data[:100])\n",
    "    ldpc_bits_r = r.pre_ldpc_data[168:]\n",
    "    print(ldpc_bits_r[:100])\n",
    "    print(r.sigma2)\n",
    "\n",
    "    \n",
    "    colors = []\n",
    "    for index in range(0,len(ldpc_bits),2):\n",
    "        if (ldpc_bits[index], ldpc_bits[index+1]) == (0, 0):\n",
    "            colors.append('r')\n",
    "        elif (ldpc_bits[index], ldpc_bits[index+1]) == (0, 1):\n",
    "            colors.append('g')\n",
    "        elif (ldpc_bits[index], ldpc_bits[index+1]) == (1, 1):\n",
    "            colors.append('b')\n",
    "        elif (ldpc_bits[index], ldpc_bits[index+1]) == (1, 0):\n",
    "            colors.append('y')\n",
    "    r.constellations = r.constellations[168//2:]\n",
    "    for index in range(0,13):\n",
    "        \n",
    "        \"\"\"plt.scatter(np.real(r.constellations[648 * index:648 * (index+1)]), np.imag(r.constellations[648 * index:648 * (index+1)]), c=colors[648 * index:648 * (index+1)])\n",
    "        plt.axhline(0, color='black', lw=0.5)\n",
    "        plt.axvline(0, color='black', lw=0.5)\n",
    "        plt.show()\"\"\"\n",
    "\n",
    "        if False:\n",
    "            plt.scatter(np.real(r.constellations[648 * index:648 * (index+1)]), np.imag(r.constellations[648 * index:648 * (index+1)]), c=colors[648 * index:648 * (index+1)])\n",
    "            plt.axhline(0, color='black', lw=0.5)\n",
    "            plt.axvline(0, color='black', lw=0.5)\n",
    "            plt.show()\n",
    "\n",
    "        if index == 30:\n",
    "            plt.scatter(np.real(r.constellations[648 * index:648 * (index+1)]), np.imag(r.constellations[648 * index:648 * (index+1)]), c=colors[648 * index:648 * (index+1)])\n",
    "            plt.axhline(0, color='black', lw=0.5)\n",
    "            plt.axvline(0, color='black', lw=0.5)\n",
    "            plt.show()\n",
    "\n",
    "        if index == 40:\n",
    "            plt.scatter(np.real(r.constellations[648 * index:648 * (index+1)]), np.imag(r.constellations[648 * index:648 * (index+1)]), c=colors[648 * index:648 * (index+1)])\n",
    "            plt.axhline(0, color='black', lw=0.5)\n",
    "            plt.axvline(0, color='black', lw=0.5)\n",
    "            plt.show()\n",
    "\n",
    "    print(\"first decoded\", r.first_decoded.shape)\n",
    "    print(\"corrected\", r.corrected.shape)\n",
    "\n",
    "    index = 0\n",
    "    print(len(ldpc_bits), len(ldpc_bits_r), len(binary_data), len(r.constellations))\n",
    "    print('1',success(ldpc_bits[0:100], ldpc_bits_r[0:100]))\n",
    "    print('2',success(ldpc_bits[100:200], ldpc_bits_r[100:200]))\n",
    "    print('3',success(ldpc_bits[200:300], ldpc_bits_r[200:300]))\n",
    "    print('4',success(ldpc_bits[300:400], ldpc_bits_r[300:400]))\n",
    "    print('5',success(ldpc_bits[400:500], ldpc_bits_r[400:500]))\n",
    "    print('5.9-6',success(ldpc_bits[490:500], ldpc_bits_r[490:500]))\n",
    "    print('6',success(ldpc_bits[500:600], ldpc_bits_r[500:600]))\n",
    "    print('7',success(ldpc_bits[600:700], ldpc_bits_r[600:700]))\n",
    "    print('8',success(ldpc_bits[700:800], ldpc_bits_r[700:800]))\n",
    "    print('9',success(ldpc_bits[800:900], ldpc_bits_r[800:900]))\n",
    "    print('10',success(ldpc_bits[900:1000], ldpc_bits_r[900:1000]))\n",
    "    print('11',success(ldpc_bits[1000:1100], ldpc_bits_r[1000:1100]))\n",
    "    print('12',success(ldpc_bits[1100:1200], ldpc_bits_r[1100:1200]))\n",
    "\n",
    "    \"\"\"for index in range(0, 40):\n",
    "        print(success(ldpc_bits[648 * 2 * index:648 * 2 * (index+1)], ldpc_bits_r[648 * 2 * index: 648 * 2 * (index+1)]))\"\"\"\n",
    "\n",
    "\n",
    "    print(\"ldpc\")\n",
    "    for index in range(0, 40):\n",
    "        print(success(binary_data[648 * index:648 * (index+1)], transmitted_bits[648 * index:648 * (index+1)]))\n",
    "\n",
    "    print(r.decode_text(binary_data))\n",
    "\n",
    "    channel_freq = r.channel_freq\n",
    "    print(r.chirp_start)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
